{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HiveCase/MLT/blob/main/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries"
      ],
      "metadata": {
        "id": "WT2nf7VJXHsH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kgvCN0n3_1p"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This assignments has two sections:\n",
        "* Linear Regression\n",
        "* Kernel Regression\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iBY90BqPXO31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1:\n",
        "\n",
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "X1nmn2q15Vzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the Boston_housing dataset for the regression problem. Run the below cell to get the following variables:\n",
        "* `Training_data` = Training data matrix of shape $(n, d)$\n",
        "* `labels` = label vector corresponding to the training data\n",
        "* `test_data` = Test data matrix of shape $(n_1, d)$ where $n_1$ is the number of examples in test dataset.\n",
        "* `test_labels` = label vector corresponding to the test data\n",
        "\n",
        "Use this dataset for the regression problem."
      ],
      "metadata": {
        "id": "aComJ_Fd5dnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import boston_housing\n",
        "Train, test = boston_housing.load_data(seed= 111)\n",
        "Training_data, labels = Train[0], Train[1]\n",
        "Test_data, test_labels = test[0], test[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53UCtcH64nsC",
        "outputId": "e725ade0-ea68-4ab7-e044-06368bf88b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1\n",
        "How many examples are there in the training dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "R0Dnj-Qha47p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "print(Training_data.shape[0])"
      ],
      "metadata": {
        "id": "vpLeerN2mGRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a784afec-3c91-4fdb-f2f7-20d6b4256555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2\n",
        "How many examples are there in the test dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "ChYFPOV5b5jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "print(Test_data.shape[0])"
      ],
      "metadata": {
        "id": "0XK7s98bb8PY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fed2fc0-dfc5-43cf-afe0-add618611061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3\n",
        "\n",
        "How many features are there in the dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYLLXlAacL5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "print(Training_data.shape[1])"
      ],
      "metadata": {
        "id": "rGvr9_jkO7NA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b9d5e2-95ee-4af5-84e7-dc2f36c02a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression model for the dataset ${\\mathbb{x}, y}$ is given as\n",
        "$$h_w(\\mathbb{x}) = w_1x^{1}+w_2x^{2}+...+w_dx^{d} =  \\mathbb{x}^Tw\n",
        "$$\n",
        "\n",
        "where $x^{i}$ is the $i^{th}$ feature, $\\mathbb{x}$ is the feature matrix of shape $(d, n)$ and $w = [w_1, w_2, ...w_d]^T$ is the weight vector.\n",
        "\n",
        "\n",
        "Notice that above model always pass through the origin but for a given dataset, best fit model need not pass through the origin. To tackle this issue, we add an intercept $w_0$ in the model and set the corresponding featrue $x^{0}$ to $1$. That is\n",
        "\n",
        "$$h_w(\\mathbb{x}) =w_0x^{0}+ w_1x^{1}+w_2x^{2}+...+w_dx^{n} =  \\mathbb{x}^Tw\n",
        "$$\n",
        "\n",
        "We call $x^{0}$ the dummy feature and set its value to 1 for each examples. Now $w$ is of shape $(d+1, 1)$ and $\\mathbb{x}$ is of shape $(d+1, n)$ where the first row of $\\mathbb{x}$ has entries as 1.\n"
      ],
      "metadata": {
        "id": "KmF4HhMmhx9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task\n",
        "\n",
        "Add the dummy feature in the feature matrix `Training_data` and test data matrix `test_data`. We will be using this new feature matrices (after adding te dummy feature) for learning the model.\n",
        "\n",
        "Note: As per your convenience, you can convert the shape of the training dataset to $(d, n)$."
      ],
      "metadata": {
        "id": "kN5fsfqfmX_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "# Add dummy feature (column of ones) to training data\n",
        "Training_data = np.concatenate((np.ones((Training_data.shape[0], 1)), Training_data), axis=1)\n",
        "\n",
        "# Add dummy feature to test data\n",
        "Test_data = np.concatenate((np.ones((Test_data.shape[0], 1)), Test_data), axis=1)\n",
        "\n",
        "# Convert the shape of the training dataset to (d, n)\n",
        "Training_data = Training_data.T\n",
        "Test_data = Test_data.T\n",
        "labels = labels.reshape(1, -1)\n",
        "test_labels = test_labels.reshape(1, -1)"
      ],
      "metadata": {
        "id": "wic4nhW47fOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4\n",
        "If the solution of optimization problem is obtained by setting the first derivative of loss function (squared loss) to zero, find the value of $w_0+w_1+...w_d$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sK4oWgqCnzgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "weights = np.linalg.inv(Training_data @ Training_data.T) @ Training_data @ labels.T\n",
        "print(np.sum(weights))"
      ],
      "metadata": {
        "id": "JORYNRkdOo55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c50bd92-d715-4b23-9ade-eb3a4ad86007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.524582464658266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5\n",
        "Find the average of the predictions made by the above model.\n",
        "\n"
      ],
      "metadata": {
        "id": "uBUor5KWp3_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "predictions = weights.T @ Training_data\n",
        "print(np.mean(predictions))"
      ],
      "metadata": {
        "id": "O2vF1aE2Rxfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e24405a-ff52-4c21-e233-26f365717f76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22.309158415841498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6\n",
        "\n",
        "Find the loss for the training data points using the above model. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "FSDbBz7ucm_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here\n",
        "# Calculate the loss\n",
        "loss = np.sqrt(np.mean((labels - predictions)**2))\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "F4jRui2VSeDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31246754-061f-4024-bb01-5ea92788dd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.552387969840813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 7\n",
        "\n",
        "Find the loss for the test data points using the above model. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "5eh8cI4PeVEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "test_predictions = weights.T @ Test_data\n",
        "\n",
        "# Calculate the loss for test data\n",
        "test_loss = np.sqrt(np.mean((test_labels - test_predictions)**2))\n",
        "print(test_loss)"
      ],
      "metadata": {
        "id": "vBMCgEIBU6v5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37996389-a8c3-4740-96a0-b99a975dd202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.327662216181637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 8\n",
        "Find the weights using the gradient descent. Use a constant learning rate of $\\eta = 10^{-10}$. Initialize the weight vector as zero vector and update the weights for 100 iterations. Enter the sum of all the weights.\n",
        "\n"
      ],
      "metadata": {
        "id": "NkeClcplfJLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights and learning rate\n",
        "eta = 1e-10\n",
        "w = np.zeros((Training_data.shape[0], 1))\n",
        "iterations = 100\n",
        "\n",
        "# Gradient descent\n",
        "for _ in range(iterations):\n",
        "    gradient = -2 * Training_data @ (labels.T - Training_data.T @ w)\n",
        "    w = w - eta * gradient\n",
        "\n",
        "print(np.sum(w))"
      ],
      "metadata": {
        "id": "QbpyGnfgWEqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34ed9d11-c50e-4668-e304-9184a2ba255d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0589590611959026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 9\n",
        "\n",
        "Find the loss for the training data points if the model is learnt using the gradient descent as in question 8. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "78ApH0oAg96X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the training data using gradient descent weights\n",
        "predictions_gd = w.T @ Training_data\n",
        "\n",
        "# Calculate the loss for training data\n",
        "loss_gd = np.sqrt(np.mean((labels - predictions_gd)**2))\n",
        "print(loss_gd)"
      ],
      "metadata": {
        "id": "oI1yIf9N8la7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb66cfa-8d6e-48d0-8bd8-51f514087655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.137273237021958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 10\n",
        "\n",
        "Find the loss for the test data points if the model is learnt using the gradient descent as in question 8. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "FA7UKT1Y3PXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data using gradient descent weights\n",
        "test_predictions_gd = w.T @ Test_data\n",
        "\n",
        "# Calculate the loss for test data\n",
        "test_loss_gd = np.sqrt(np.mean((test_labels - test_predictions_gd)**2))\n",
        "print(test_loss_gd)"
      ],
      "metadata": {
        "id": "tevVzIIj3SZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "051f9b38-00fa-4be2-868f-14ef562719e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.964491250062146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 11\n",
        "Find the weights using the stochastic gradient descent. Use a constant learning rate of $\\eta = 10^{-8}$. Initialize the weight vector as zero vector and update the weights for 1000 iterations. . Take the batch size of $⌈\\text{number of samples}/5⌉ $. For sampling the batch examples in $ith$ iteration, set seed at $i$. The final weight is the last updated weight. Do not take the avearge of weights updated in all the iterations. Enter the sum of all the weights.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-AoLsBKc31Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize weights, learning rate, and batch size\n",
        "eta = 1e-8\n",
        "w = np.zeros((Training_data.shape[0], 1))\n",
        "iterations = 1000\n",
        "batch_size = int(np.ceil(Training_data.shape[1] / 5))\n",
        "\n",
        "# Stochastic gradient descent\n",
        "for i in range(iterations):\n",
        "    np.random.seed(i)\n",
        "    indices = np.random.choice(Training_data.shape[1], batch_size, replace=False)\n",
        "    X_batch = Training_data[:, indices]\n",
        "    y_batch = labels[:, indices]\n",
        "    gradient = -2 * X_batch @ (y_batch.T - X_batch.T @ w)\n",
        "    w = w - eta * gradient\n",
        "\n",
        "print(np.sum(w))"
      ],
      "metadata": {
        "id": "R4odop9yF9VY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af18a01c-a72c-450a-d4b9-84ecb1a12f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10333558885089422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 12\n",
        "\n",
        "Find the loss for the training data points if the model is learnt using the stochastic gradient descent as in question 11. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "yPzJLciH4NrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the training data using SGD weights\n",
        "predictions_sgd = w.T @ Training_data\n",
        "\n",
        "# Calculate the loss for training data\n",
        "loss_sgd = np.sqrt(np.mean((labels - predictions_sgd)**2))\n",
        "print(loss_sgd)"
      ],
      "metadata": {
        "id": "w9usLAPeLNkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f959f6a-a5c2-41d0-f4a1-fe918cf0da58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.622983379043724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 13\n",
        "\n",
        "Find the loss for the test data points if the model is learnt using the stochastic gradient descent as in question 11. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n"
      ],
      "metadata": {
        "id": "rfeamQM94x_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data using SGD weights\n",
        "test_predictions_sgd = w.T @ Test_data\n",
        "\n",
        "# Calculate the loss for test data\n",
        "test_loss_sgd = np.sqrt(np.mean((test_labels - test_predictions_sgd)**2))\n",
        "print(test_loss_sgd)"
      ],
      "metadata": {
        "id": "oF1xpNH845iH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4add2cff-9753-4e53-f89a-ee9d79dff3b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.340072147255404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2:\n",
        "\n",
        "**kernel Regression**"
      ],
      "metadata": {
        "id": "muMOKLvY5D9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will generate the synthetic dataset for the kernel regression problem. Run the following cell to get the following variables:\n",
        "\n",
        "`X` = Training data matrix of shape $(n, d)$. In the given dataset $d = 1$.\n",
        "\n",
        "`y` = label vector corresponding to the training dataset"
      ],
      "metadata": {
        "id": "pDAKRJua6rCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(seed = 101)\n",
        "X = np.arange(-2, 2, 0.01).reshape(-1, 1)\n",
        "y = X**3 + rng.normal(0, 1, X.shape[0]).reshape(-1, 1)\n"
      ],
      "metadata": {
        "id": "_WgICXZSnra0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 14\n",
        "\n",
        "Plot the scatter plot between feature and the labels. Enter your answer as 0.\n",
        "\n"
      ],
      "metadata": {
        "id": "y_-9lyPm8aaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Enter your solution here"
      ],
      "metadata": {
        "id": "B12Nc2Sv80_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 15\n",
        "How many examples are there in the training dataset?\n",
        "\n"
      ],
      "metadata": {
        "id": "E3e-gQHg8z8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape[0])"
      ],
      "metadata": {
        "id": "xGeqMCV57ZJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7670b185-aecc-49aa-9231-c36ca6165b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task:\n",
        "\n",
        "Add the dummy feature in the feature matrix `X`and reshape it to the shape $(d, n)$."
      ],
      "metadata": {
        "id": "uPifeX-K9zuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
        "\n",
        "# Reshape X to (d, n)\n",
        "X = X.T"
      ],
      "metadata": {
        "id": "yduBBJQgujfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 16\n",
        "\n",
        "Our task is to apply the kernel regression with polynomial kernel of degree 3. We know that weight vector can be written as\n",
        "\n",
        "$$w = \\phi(\\mathbb{x})\\alpha$$\n",
        "\n",
        "let us call the vector $\\alpha$ as coefficient vector. Find the sum of elements in the coefficient vector.\n",
        "\n"
      ],
      "metadata": {
        "id": "HQtBOQua_HQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def polynomial_kernel(x1, x2, degree=3):\n",
        "    return (1 + np.dot(x1.T, x2)) ** degree\n",
        "\n",
        "# Construct the kernel matrix\n",
        "K = np.zeros((X.shape[1], X.shape[1]))\n",
        "for i in range(X.shape[1]):\n",
        "    for j in range(X.shape[1]):\n",
        "        K[i, j] = polynomial_kernel(X[:, i].reshape(-1, 1), X[:, j].reshape(-1, 1))\n",
        "\n",
        "# Calculate alpha\n",
        "alpha = np.linalg.inv(K) @ y\n",
        "print(np.sum(alpha))\n"
      ],
      "metadata": {
        "id": "CVMDkgkNqCBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f7d84c-8176-41f5-f7b0-cc54b1681d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-7ae01be25c66>:8: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  K[i, j] = polynomial_kernel(X[:, i].reshape(-1, 1), X[:, j].reshape(-1, 1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 17\n",
        "\n",
        "Find the sum of the predictions made by the kernel regression model of degree 3.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xq0YtsGjA7IK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_kernel = K @ alpha\n",
        "print(np.sum(predictions_kernel))"
      ],
      "metadata": {
        "id": "YAqln4GZ05dg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d71284-e9a7-4e45-d549-dd139396d68e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35328.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 18\n",
        "\n",
        "Find the loss for the training data points. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "pXRpijIeCcSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_kernel = np.sqrt(np.mean((y - predictions_kernel)**2))\n",
        "print(loss_kernel)"
      ],
      "metadata": {
        "id": "8_i2Th-g1ToW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "496a039d-b849-4503-c593-710100779ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "750.9331570794703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test dataset\n",
        "\n",
        "run the following cell to get the test data matrix `X_test` and corresponding label vector `y_test`."
      ],
      "metadata": {
        "id": "nGpw3zpI65rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(seed = 102)\n",
        "Xnew = np.arange(-2, 2, 0.03)\n",
        "ynew = Xnew**3 + rng.normal(0, 1.5, Xnew.shape[0])\n",
        "X_test = np.column_stack((np.ones(Xnew.shape[0]), Xnew.reshape(-1, 1))).T\n",
        "y_test = ynew.reshape(-1, 1)\n",
        "plt.scatter(Xnew,ynew)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "fLNDYH_B67kN",
        "outputId": "474421bb-9672-4673-a9ef-22cf454cf759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x79a993c5ded0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 19\n",
        "\n",
        "Find the loss for the test data points. Consider the loss to be defined as\n",
        "\n",
        "$$ \\sqrt{\\dfrac{1}{n}\\sum\\limits_{i=1}^{n} (y_i- \\hat{y}_i)^2}\n",
        "$$\n",
        "\n",
        "Where $\\hat{y}_i$ is the prediction for $i^{th}$ data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "5vlunIBzDI1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the test kernel matrix\n",
        "K_test = np.zeros((X_test.shape[1], X.shape[1]))\n",
        "for i in range(X_test.shape[1]):\n",
        "    for j in range(X.shape[1]):\n",
        "        K_test[i, j] = polynomial_kernel(X_test[:, i].reshape(-1, 1), X[:, j].reshape(-1, 1))\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions_test_kernel = K_test @ alpha\n",
        "\n",
        "# Calculate the loss for test data\n",
        "test_loss_kernel = np.sqrt(np.mean((y_test - predictions_test_kernel)**2))\n",
        "print(test_loss_kernel)"
      ],
      "metadata": {
        "id": "_RxSPslY7joK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad81497-49fa-4597-cc4f-e3eb757b64cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-a8fad710f912>:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  K_test[i, j] = polynomial_kernel(X_test[:, i].reshape(-1, 1), X[:, j].reshape(-1, 1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "765.8660210319501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bvxV7FfTuGhP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}